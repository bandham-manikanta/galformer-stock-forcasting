{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from fredapi import Fred\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')  # Options: 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'FATAL'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inference_data(company_df, sequence_length=60):\n",
    "    \"\"\"\n",
    "    Prepare input data for inference .\n",
    "    Args:\n",
    "        company_df (DataFrame): The DataFrame for a specific company.\n",
    "        sequence_length (int): The number of past days to consider as input.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: The input data ready for prediction.\n",
    "    \"\"\"\n",
    "    # Ensure data is sorted by date\n",
    "    company_df = company_df.sort_index()\n",
    "\n",
    "    # Select relevant input features (exclude targets)\n",
    "    input_features = company_df.filter(regex=\"^(?!.*target).*\").values\n",
    "\n",
    "    # Take the last `sequence_length` days as input for prediction\n",
    "    if len(input_features) >= sequence_length:\n",
    "        input_sequence = input_features[-sequence_length:]\n",
    "        return np.expand_dims(input_sequence, axis=0)  # Add batch dimension\n",
    "    else:\n",
    "        raise ValueError(\"Insufficient data for inference (less than sequence length).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_for_all_companies(all_dfs, model, ticker, sequence_length=60):\n",
    "    \"\"\"\n",
    "    Get predictions for all companies using the trained model.\n",
    "    Args:\n",
    "        all_dfs (dict): Dictionary of company DataFrames.\n",
    "        model: Trained LSTM model.\n",
    "        sequence_length (int): Number of past days to consider as input.\n",
    "\n",
    "    Returns:\n",
    "        dict: Predictions for each company.\n",
    "    \"\"\"\n",
    "    predictions = {}\n",
    "\n",
    "    all_dfs = {k: v for k, v in all_dfs.items() if k == \"df_\"+ticker}\n",
    "    \n",
    "    for company, df in all_dfs.items():\n",
    "        try:\n",
    "            # Prepare data for inference\n",
    "            input_data = prepare_inference_data(df, sequence_length=sequence_length)\n",
    "            \n",
    "            # Make predictions\n",
    "            pred = model.predict(input_data)\n",
    "            \n",
    "            # Store predictions\n",
    "            predictions[company] = pred.flatten()  # Flatten the array for readability\n",
    "        \n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping {company}: {e}\")\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    start_date = (datetime.datetime.today() - datetime.timedelta(days=100)).strftime('%Y-%m-%d')\n",
    "    end_date = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Example list of S&P 500 tickers (full list can be obtained elsewhere)\n",
    "    tickers = [\"AAPL\", \"NVDA\", \"MSFT\", \"GOOG\", \"GOOGL\", \"AMZN\", \"META\", \"AVGO\", \"LLY\", \"TSLA\", \n",
    "                    \"WMT\", \"JPM\", \"V\", \"XOM\", \"UNH\", \"ORCL\", \"MA\", \"HD\", \"PG\", \"COST\", \"JNJ\", \n",
    "                    \"NFLX\", \"ABBV\", \"BAC\", \"KO\", \"CRM\", \"CVX\", \"MRK\", \"TMUS\", \"AMD\", \"PEP\", \n",
    "                    \"ACN\", \"LIN\", \"TMO\", \"MCD\", \"CSCO\", \"ADBE\", \"WFC\", \"IBM\", \"GE\", \"ABT\", \n",
    "                    \"DHR\", \"AXP\", \"MS\", \"CAT\", \"NOW\", \"QCOM\", \"PM\", \"ISRG\", \"VZ\"]\n",
    "\n",
    "    # Download data for all tickers at once\n",
    "    stock_price_data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker')\n",
    "\n",
    "    stock_data = stock_price_data.copy()\n",
    "\n",
    "    # Flatten MultiIndex columns in stock_data\n",
    "    stock_data.columns = ['_'.join(col).strip() for col in stock_data.columns.values]\n",
    "\n",
    "    # Convert index to DatetimeIndex if not already\n",
    "    if not isinstance(stock_data.index, pd.DatetimeIndex):\n",
    "        stock_data.index = pd.to_datetime(stock_data.index)\n",
    "\n",
    "    # Sort by date\n",
    "    stock_data.sort_index(inplace=True)\n",
    "\n",
    "    with open('updated_all_dfs.pkl', 'rb') as file:\n",
    "        loaded_data = pickle.load(file)\n",
    "    \n",
    "    inference_data = {}\n",
    "\n",
    "    for comp in tickers:\n",
    "        ll = 'df_'+comp\n",
    "        reg = '^'+comp+'_'\n",
    "        filtered_data = stock_data.filter(regex=reg)\n",
    "        last_rows = loaded_data[ll].tail(filtered_data.shape[0])\n",
    "        ind_ = filtered_data.index\n",
    "        last_rows.index = ind_\n",
    "        merged_df = filtered_data.join(last_rows, how='left', lsuffix='', rsuffix='_r')\n",
    "        merged_df = merged_df[[col for col in merged_df.columns if not col.endswith('_r')]]\n",
    "        inference_data[ll] = merged_df\n",
    "            \n",
    "    return inference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_predictions(ticker):\n",
    "    \n",
    "    inference_data = data_loading()\n",
    "    print(inference_data.keys())\n",
    "    print(\"Loading data Completed\")    \n",
    "    new_model = load_model('lstm_model_general.h5')\n",
    "    print(\"Loading LSTM model Completed\")\n",
    "    predictions = get_predictions_for_all_companies(inference_data, new_model,ticker, sequence_length=60)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    lstm_preds = lstm_predictions(\"AMZN\")\n",
    "    return lstm_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                       0%                       ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n",
      "2024-12-12 16:06:46.785450: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-12-12 16:06:46.786247: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['df_AAPL', 'df_NVDA', 'df_MSFT', 'df_GOOG', 'df_GOOGL', 'df_AMZN', 'df_META', 'df_AVGO', 'df_LLY', 'df_TSLA', 'df_WMT', 'df_JPM', 'df_V', 'df_XOM', 'df_UNH', 'df_ORCL', 'df_MA', 'df_HD', 'df_PG', 'df_COST', 'df_JNJ', 'df_NFLX', 'df_ABBV', 'df_BAC', 'df_KO', 'df_CRM', 'df_CVX', 'df_MRK', 'df_TMUS', 'df_AMD', 'df_PEP', 'df_ACN', 'df_LIN', 'df_TMO', 'df_MCD', 'df_CSCO', 'df_ADBE', 'df_WFC', 'df_IBM', 'df_GE', 'df_ABT', 'df_DHR', 'df_AXP', 'df_MS', 'df_CAT', 'df_NOW', 'df_QCOM', 'df_PM', 'df_ISRG', 'df_VZ'])\n",
      "Loading data Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 16:06:46.786861: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-12-12 16:06:46.887176: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-12-12 16:06:46.887852: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-12-12 16:06:46.888465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LSTM model Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 16:06:47.064281: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-12-12 16:06:47.065140: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-12-12 16:06:47.065987: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-12-12 16:06:47.192311: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-12-12 16:06:47.193118: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-12-12 16:06:47.193873: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 445ms/step\n"
     ]
    }
   ],
   "source": [
    "vals = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_AMZN'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56.801254, 56.732742, 56.705776, 56.67417 , 56.811554, 56.710457,\n",
       "       56.703117, 56.638515, 56.915035, 56.75484 , 56.550545, 56.290154,\n",
       "       56.596928, 56.83077 , 56.909447, 56.971436, 56.834164, 56.673832,\n",
       "       57.11828 , 56.7683  , 56.512383, 56.873047, 56.874454, 56.97342 ,\n",
       "       56.850136], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals['df_AMZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
